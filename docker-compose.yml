# Usage
#   Setup:              ./setup.sh
#   Start:              docker compose up
#   Migrate DB:         ./migrate-local.sh
#   Stop:               docker compose down
#   Destroy:            docker compose down --volumes --remove-orphans
#   Reset everything:  ./reset.sh

name: pgonrails

services:

  site:
    build:
      context: ./site
      dockerfile: dev.Dockerfile
    restart: unless-stopped
    ports:
      - ${SITE_PORT}:${SITE_PORT}
    volumes:
      - ./site:/app
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:${SITE_PORT}/health" ]
      timeout: 10s
      interval: 5s
      retries: 3
    depends_on:
      db:
        condition: service_healthy
      storage:
        condition: service_healthy
    environment:
      HOSTNAME: ${SITE_LISTEN}
      PORT: ${SITE_PORT}

      NEXT_PUBLIC_SITE_URL: http://localhost:${SITE_PORT}
      NEXT_PUBLIC_SUPABASE_URL: http://localhost:${KONG_PORT}
      NEXT_PUBLIC_SUPABASE_ANON_KEY: ${ANON_KEY}
      NEXT_PUBLIC_UPDATE_PASSWORD_REQUIRE_REAUTHENTICATION: ${GOTRUE_SECURITY_UPDATE_PASSWORD_REQUIRE_REAUTHENTICATION}
      
      SUPABASE_URL: http://${KONG_HOST}:${KONG_PORT}
      SUPABASE_SERVICE_ROLE_KEY: ${SERVICE_ROLE_KEY}

      DB_PRIVATE_CONNECTION_STRING: postgres://postgres:${DB_SUPERUSER_PASSWORD}@${DB_HOST}:${DB_PORT}/${DB_NAME}

  studio:
    build: ./studio
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "node", "-e", "fetch('http://studio:${STUDIO_PORT}/api/platform/profile').then((r) => {if (r.status !== 200) throw new Error(r.status)})" ]
      timeout: 10s
      interval: 5s
      retries: 3
    environment:
      HOSTNAME: ${STUDIO_LISTEN}
      PORT: ${STUDIO_PORT}
      SUPABASE_URL: http://${KONG_HOST}:${KONG_PORT}
      SUPABASE_PUBLIC_URL: http://localhost:${KONG_PORT}
      STUDIO_PG_META_URL: http://${META_HOST}:${META_PORT}

      SUPABASE_ANON_KEY: ${ANON_KEY}
      SUPABASE_SERVICE_KEY: ${SERVICE_ROLE_KEY}
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      POSTGRES_PASSWORD: ${DB_SUPERUSER_PASSWORD}
      AUTH_JWT_SECRET: ${JWT_SECRET}

      DEFAULT_ORGANIZATION_NAME: My Org
      DEFAULT_PROJECT_NAME: PG On Rails
      

  kong:
    build: ./kong
    restart: unless-stopped
    ports:
      - ${KONG_PORT}:${KONG_PORT}/tcp
    healthcheck:
      test: [ "CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:${KONG_STATUS_PORT}/status" ]
      timeout: 10s
      interval: 5s
      retries: 3
    environment:
      KONG_PROXY_LISTEN: ${KONG_LISTEN}:${KONG_PORT} reuseport backlog=16384, 0.0.0.0:${KONG_PORT} reuseport backlog=16384
      KONG_STATUS_LISTEN: "[::]:${KONG_STATUS_PORT}, 0.0.0.0:${KONG_STATUS_PORT}"
      # To find the IP address of services, Kong looks for SRV records by default, which don't exist in the Docker Compose internal network DNS
      KONG_DNS_ORDER: LAST,A,CNAME

      KONG_DATABASE: "off"
      KONG_DECLARATIVE_CONFIG: /home/kong/kong.yml
      KONG_PLUGINS: request-transformer,cors,key-auth,acl,basic-auth
      KONG_NGINX_PROXY_PROXY_BUFFER_SIZE: 160k
      KONG_NGINX_PROXY_PROXY_BUFFERS: 64 160k
      KONG_NGINX_WORKER_PROCESSES: 2

      SUPABASE_ANON_KEY: ${ANON_KEY}
      SUPABASE_SERVICE_KEY: ${SERVICE_ROLE_KEY}
      DASHBOARD_USERNAME: ${DASHBOARD_USERNAME}
      DASHBOARD_PASSWORD: ${DASHBOARD_PASSWORD}

      AUTH_HOST: ${AUTH_HOST}
      AUTH_PORT: ${AUTH_PORT}
      REST_HOST: ${REST_HOST}
      REST_PORT: ${REST_PORT}
      META_HOST: ${META_HOST}
      META_PORT: ${META_PORT}
      STUDIO_HOST: ${STUDIO_HOST}
      STUDIO_PORT: ${STUDIO_PORT}
      FUNCTIONS_HOST: ${FUNCTIONS_HOST}
      FUNCTIONS_PORT: ${FUNCTIONS_PORT}
      REALTIME_HOST: ${REALTIME_HOST}
      REALTIME_PORT: ${REALTIME_PORT}
      STORAGE_HOST: ${STORAGE_HOST}
      STORAGE_PORT: ${STORAGE_PORT}

  auth:
    build: ./auth
    restart: unless-stopped
    volumes:
      - ./auth/templates:/home/mailer/templates
    depends_on:
      db:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:${AUTH_PORT}/health" ]
      timeout: 5s
      interval: 5s
      retries: 3
    environment:
      GOTRUE_API_HOST: ${AUTH_LISTEN}
      GOTRUE_API_PORT: ${AUTH_PORT}

      GOTRUE_DB_DRIVER: postgres
      GOTRUE_DB_DATABASE_URL: postgres://supabase_auth_admin:${DB_AUTH_PASSWORD}@${DB_HOST}:${DB_PORT}/${DB_NAME}

      API_EXTERNAL_URL: http://localhost:${KONG_PORT}
      GOTRUE_SITE_URL: http://localhost:${SITE_PORT}

      GOTRUE_JWT_ADMIN_ROLES: service_role
      GOTRUE_JWT_AUD: authenticated
      GOTRUE_JWT_DEFAULT_GROUP_NAME: authenticated
      GOTRUE_JWT_EXP: ${JWT_EXPIRY}
      GOTRUE_JWT_SECRET: ${JWT_SECRET}

      # When set to "true", to change their password, users must provide a OTP from their email or phone
      GOTRUE_SECURITY_UPDATE_PASSWORD_REQUIRE_REAUTHENTICATION: ${GOTRUE_SECURITY_UPDATE_PASSWORD_REQUIRE_REAUTHENTICATION}

      # Set to "true" to disable emails, which can be useful in development. Set to "false" to require email confirmations.
      GOTRUE_MAILER_AUTOCONFIRM: true

      GOTRUE_SMTP_ADMIN_EMAIL: ${SMTP_ADMIN_EMAIL}
      GOTRUE_SMTP_HOST: ${SMTP_HOST}
      GOTRUE_SMTP_PORT: ${SMTP_PORT}
      GOTRUE_SMTP_USER: ${SMTP_USER}
      GOTRUE_SMTP_PASS: ${SMTP_PASS}
      GOTRUE_SMTP_SENDER_NAME: "PG On Rails"

      GOTRUE_MAILER_EXTERNAL_HOSTS: ${KONG_HOST},${SITE_HOST},localhost

      GOTRUE_MAILER_URLPATHS_INVITE: /auth/v1/verify
      GOTRUE_MAILER_URLPATHS_CONFIRMATION: /auth/v1/verify
      GOTRUE_MAILER_URLPATHS_RECOVERY: /auth/v1/verify
      GOTRUE_MAILER_URLPATHS_EMAIL_CHANGE: /auth/v1/verify

      # The default subject for the OTP email is cringe and needs to be overridden
      GOTRUE_MAILER_SUBJECTS_REAUTHENTICATION: "Your One-Time Passcode"

      GOTRUE_MAILER_TEMPLATES_INVITE: ${AUTH_LOCAL_MAILER_TEMPLATES_URL}/invite.html
      GOTRUE_MAILER_TEMPLATES_CONFIRMATION: ${AUTH_LOCAL_MAILER_TEMPLATES_URL}/confirmation.html
      GOTRUE_MAILER_TEMPLATES_RECOVERY: ${AUTH_LOCAL_MAILER_TEMPLATES_URL}/recovery.html
      GOTRUE_MAILER_TEMPLATES_MAGIC_LINK: ${AUTH_LOCAL_MAILER_TEMPLATES_URL}/magiclink.html
      GOTRUE_MAILER_TEMPLATES_EMAIL_CHANGE: ${AUTH_LOCAL_MAILER_TEMPLATES_URL}/emailchange.html
      GOTRUE_MAILER_TEMPLATES_REAUTHENTICATION: ${AUTH_LOCAL_MAILER_TEMPLATES_URL}/reauthentication.html
      GOTRUE_MAILER_TEMPLATES_PASSWORD_CHANGED_NOTIFICATION: ${AUTH_LOCAL_MAILER_TEMPLATES_URL}/passwordchanged.html
      GOTRUE_MAILER_TEMPLATES_EMAIL_CHANGED_NOTIFICATION: ${AUTH_LOCAL_MAILER_TEMPLATES_URL}/emailchanged.html
      GOTRUE_MAILER_TEMPLATES_PHONE_CHANGED_NOTIFICATION: ${AUTH_LOCAL_MAILER_TEMPLATES_URL}/phonechanged.html
      GOTRUE_MAILER_TEMPLATES_IDENTITY_LINKED_NOTIFICATION: ${AUTH_LOCAL_MAILER_TEMPLATES_URL}/identitylinked.html
      GOTRUE_MAILER_TEMPLATES_IDENTITY_UNLINKED_NOTIFICATION: ${AUTH_LOCAL_MAILER_TEMPLATES_URL}/identityunlinked.html
      GOTRUE_MAILER_TEMPLATES_MFA_FACTOR_ENROLLED_NOTIFICATION: ${AUTH_LOCAL_MAILER_TEMPLATES_URL}/mfafactorenrolled.html
      GOTRUE_MAILER_TEMPLATES_MFA_FACTOR_UNENROLLED_NOTIFICATION: ${AUTH_LOCAL_MAILER_TEMPLATES_URL}/mfafactorunenrolled.html
  rest:
    build:
      context: ./rest
      dockerfile: dev.Dockerfile
    restart: unless-stopped
    depends_on:
      db:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${REST_ADMIN_PORT}/live"]
      timeout: 5s
      interval: 5s
      retries: 3
    environment:
      PGRST_SERVER_HOST: ${REST_LISTEN}
      PGRST_SERVER_PORT: ${REST_PORT}
      PGRST_ADMIN_SERVER_HOST: ${REST_LISTEN}
      PGRST_ADMIN_SERVER_PORT: ${REST_ADMIN_PORT}

      PGRST_DB_URI: postgres://authenticator:${DB_AUTHENTICATOR_PASSWORD}@${DB_HOST}:${DB_PORT}/${DB_NAME}
      PGRST_DB_SCHEMAS: public,storage,graphql_public
      PGRST_DB_ANON_ROLE: anon
      PGRST_JWT_SECRET: ${JWT_SECRET}
      PGRST_DB_USE_LEGACY_GUCS: false
      PGRST_APP_SETTINGS_JWT_SECRET: ${JWT_SECRET}
      PGRST_APP_SETTINGS_JWT_EXP: ${JWT_EXPIRY}

  realtime:
    # Realtime needs a tenant id as the subdomain in every request. The docker compose internal network DNS
    # doesn't allow this dynamically just using the service name (*.realtime). But explicitly naming the container
    # will route requests there, achieving the necessary effect for our single self-hosted tenant.
    container_name: ${DEFAULT_TENANT}.pgonrails-realtime
    build: ./realtime
    restart: unless-stopped
    depends_on:
      db:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "curl", "-sSfL", "--head", "-o", "/dev/null", "-H", "Authorization: Bearer ${ANON_KEY}", "http://localhost:${REALTIME_PORT}/api/tenants/${DEFAULT_TENANT}/health" ]
      timeout: 5s
      interval: 5s
      retries: 3
    environment:
      ERL_AFLAGS: -proto_dist inet6_tcp # Use ipv6
      PORT: ${REALTIME_PORT}

      DB_USER: supabase_admin
      DB_PASSWORD: ${DB_SUPERUSER_PASSWORD}
      DB_HOST: ${DB_HOST}
      DB_PORT: ${DB_PORT}
      DB_NAME: ${DB_NAME}
      DB_AFTER_CONNECT_QUERY: "SET search_path TO _realtime"

      DB_ENC_KEY: ${REALTIME_DB_ENC_KEY}
      SECRET_KEY_BASE: ${REALTIME_SECRET_KEY_BASE}
      API_JWT_SECRET: ${JWT_SECRET}
      DNS_NODES: "''"
      RLIMIT_NOFILE: 10000
      APP_NAME: realtime
      SELF_HOST_TENANT_NAME: ${DEFAULT_TENANT}
      SEED_SELF_HOST: true
      RUN_JANITOR: true

  storage:
    build: ./storage
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://storage:${STORAGE_PORT}/status" ]
      timeout: 5s
      interval: 5s
      retries: 3
    depends_on:
      db:
        condition: service_healthy
      rest:
        condition: service_started
      minio:
        condition: service_started
    environment:
      # Server
      SERVER_HOST: ${STORAGE_LISTEN}
      SERVER_PORT: ${STORAGE_PORT}
      SERVER_ADMIN_PORT: ${STORAGE_ADMIN_PORT}

      # Auth
      ANON_KEY: ${ANON_KEY}
      SERVICE_KEY: ${SERVICE_ROLE_KEY}
      AUTH_JWT_SECRET: ${JWT_SECRET}
      AUTH_JWT_ALGORITHM: HS256

      # Database
      DATABASE_URL: postgres://supabase_storage_admin:${DB_STORAGE_PASSWORD}@${DB_HOST}:${DB_PORT}/${DB_NAME}
      DATABASE_POOL_URL: postgres://supabase_storage_admin:${DB_STORAGE_PASSWORD}@${PGBOUNCER_HOST}:${PGBOUNCER_PORT}/${DB_NAME}
      DATABASE_CONNECTION_TIMEOUT: 3000

      # Migrations
      DB_INSTALL_ROLES: false # set to false if you want to manage roles yourself
      DB_ALLOW_MIGRATION_REFRESH: false
      DB_ANON_ROLE: anon
      DB_SERVICE_ROLE: service_role
      DB_AUTHENTICATED_ROLE: authenticated
      DB_SUPER_USER: postgres

      # S3 Backend
      STORAGE_BACKEND: s3
      STORAGE_S3_ENDPOINT: http://${S3_HOST}:${S3_PORT}
      STORAGE_S3_FORCE_PATH_STYLE: true
      STORAGE_S3_MAX_SOCKETS: 200
      STORAGE_S3_REGION: default-region
      STORAGE_S3_BUCKET: ${STORAGE_S3_BUCKET}  # name of top-level bucket. objects are stored in a structure of <top-level-bucket>/<tenant>/<supabase-bucket>/<object>
      TENANT_ID: ${DEFAULT_TENANT}

      AWS_ACCESS_KEY_ID: ${S3_ID}
      AWS_SECRET_ACCESS_KEY: ${S3_SECRET}

      # Upload
      FILE_SIZE_LIMIT: 52428800
      UPLOAD_FILE_SIZE_LIMIT: 524288000
      UPLOAD_FILE_SIZE_LIMIT_STANDARD: 52428800
      UPLOAD_SIGNED_URL_EXPIRATION_TIME: 120

      # TUS Resumable Upload Protocol
      TUS_URL_PATH: /upload/resumable
      TUS_URL_EXPIRY_MS: 3600000
      TUS_PART_SIZE: 50

      # Image Transformation
      IMAGE_TRANSFORMATION_ENABLED: true
      IMAGE_TRANSFORMATION_LIMIT_MIN_SIZE: 0
      IMAGE_TRANSFORMATION_LIMIT_MAX_SIZE: 2000

      IMGPROXY_URL: http://${IMGPROXY_HOST}:${IMGPROXY_PORT}
      IMGPROXY_REQUEST_TIMEOUT: 15
      IMGPROXY_HTTP_MAX_SOCKETS: 500

      # S3 Protocol
      S3_PROTOCOL_ACCESS_KEY_ID: 625729a08b95bf1b7ff351a663f3a23c #???
      S3_PROTOCOL_ACCESS_KEY_SECRET: 850181e4652dd023b7a98c58ae0d2d34bd487ee0cc3254aed6eda37307425907 #???

      # PostgREST
      POSTGREST_URL: http://${REST_HOST}:${REST_PORT}
      PGRST_JWT_SECRET: ${JWT_SECRET}
      
  imgproxy:
    build: ./imgproxy
    restart: unless-stopped
    depends_on:
      minio:
        condition: service_started
    healthcheck:
      test: [ "CMD", "imgproxy", "health" ]
      timeout: 5s
      interval: 5s
      retries: 3
    environment:
      IMGPROXY_BIND: ${IMGPROXY_LISTEN}:${IMGPROXY_PORT}

      IMGPROXY_USE_S3: true
      IMGPROXY_S3_ENDPOINT: http://${S3_HOST}:${S3_PORT}
      AWS_ACCESS_KEY_ID: ${S3_ID}
      AWS_SECRET_ACCESS_KEY: ${S3_SECRET}

      IMGPROXY_USE_ETAG: true
      IMGPROXY_AUTO_WEBP: true
      IMGPROXY_JPEG_PROGRESSIVE: true
      IMGPROXY_IGNORE_SSL_VERIFICATION: true
      
  minio:
    build: ./minio
    restart: unless-stopped
    ports:
      - ${S3_PORT}:${S3_PORT}
      - ${S3_CONSOLE_PORT}:${S3_CONSOLE_PORT}
    volumes:
      - ./volumes/storage:/data:z
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://minio:9000/minio/health/live" ]
      interval: 2s
      timeout: 10s
      retries: 5
    environment:
      MINIO_ROOT_USER: ${S3_ID}
      MINIO_ROOT_PASSWORD: ${S3_SECRET}
      STORAGE_S3_BUCKET: ${STORAGE_S3_BUCKET}
    
  meta:
    build: ./meta
    restart: unless-stopped
    depends_on:
      db:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "node", "-e", "fetch('http://localhost:${META_PORT}/health').then((r) => {if (r.status !== 200) throw new Error(r.status)})"]
      interval: 5s
      timeout: 5s
      retries: 3
    environment:
      PG_META_HOST: ${META_LISTEN}
      PG_META_PORT: ${META_PORT}

      PG_META_DB_USER: supabase_admin
      PG_META_DB_PASSWORD: ${DB_SUPERUSER_PASSWORD}
      PG_META_DB_HOST: ${DB_HOST}
      PG_META_DB_PORT: ${DB_PORT}
      PG_META_DB_NAME: ${DB_NAME}

  functions:
    build: ./functions
    restart: unless-stopped
    volumes:
      - ./functions/functions:/home/deno/functions
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${FUNCTIONS_PORT}/health"]
      interval: 5s
      timeout: 5s
      retries: 3
    environment:
      EDGE_RUNTIME_LISTEN: ${FUNCTIONS_LISTEN}
      EDGE_RUNTIME_PORT: ${FUNCTIONS_PORT}

      SUPABASE_DB_URL: postgresql://postgres:${DB_SUPERUSER_PASSWORD}@${DB_HOST}:${DB_PORT}/${DB_NAME}
      SUPABASE_URL: http://${KONG_HOST}:${KONG_PORT}
      
      SUPABASE_ANON_KEY: ${ANON_KEY}
      SUPABASE_SERVICE_ROLE_KEY: ${SERVICE_ROLE_KEY}

      JWT_SECRET: ${JWT_SECRET}
      # TODO: Allow configuring VERIFY_JWT per function. This PR might help: https://github.com/supabase/cli/pull/786
      VERIFY_JWT: false

  db:
    build: ./db
    restart: unless-stopped
    ports:
      - ${DB_PORT}:${DB_PORT}
    volumes:
      - ./volumes/db/data:/var/lib/postgresql/data:Z
    healthcheck:
      test: [ "CMD", "pg_isready", "-U", "postgres", "-h", "localhost" ]
      interval: 5s
      timeout: 5s
      retries: 10
    environment:
      LISTEN_ADDRESSES: ${DB_LISTEN}
      PGPORT: ${DB_PORT}
      POSTGRES_PORT: ${DB_PORT}

      # "POSTGRES_HOST" here means a local socket address inside the container to run on and perform setup migrations
      POSTGRES_HOST: /var/run/postgresql
      PGPASSWORD: ${DB_SUPERUSER_PASSWORD}
      POSTGRES_PASSWORD: ${DB_SUPERUSER_PASSWORD}
      PGDATABASE: ${DB_NAME}
      POSTGRES_DB: ${DB_NAME}

      DB_AUTHENTICATOR_PASSWORD: ${DB_AUTHENTICATOR_PASSWORD}
      DB_PGBOUNCER_PASSWORD: ${DB_PGBOUNCER_PASSWORD}
      DB_AUTH_PASSWORD: ${DB_AUTH_PASSWORD}
      DB_WEBHOOKS_PASSWORD: ${DB_WEBHOOKS_PASSWORD}
      DB_STORAGE_PASSWORD: ${DB_STORAGE_PASSWORD}

      PGDATA: /var/lib/postgresql/data/pgdata
      JWT_SECRET: ${JWT_SECRET}
      JWT_EXP: ${JWT_EXPIRY}

  pgbouncer:
    build: ./pgbouncer
    restart: unless-stopped
    ports:
      - 6432:${PGBOUNCER_PORT}
    depends_on:
      db:
        condition: service_healthy
    environment:
      LISTEN_ADDR: ${PGBOUNCER_LISTEN}
      LISTEN_PORT: ${PGBOUNCER_PORT}
      
      DB_USER: pgbouncer
      DB_PASSWORD: ${DB_PGBOUNCER_PASSWORD}
      DB_HOST: ${DB_HOST}
      DB_PORT: ${DB_PORT}

      AUTH_QUERY: SELECT * FROM pgbouncer.get_auth($1)
      AUTH_TYPE: scram-sha-256
      POOL_MODE: transaction
      MAX_CLIENT_CONN: 100
      DEFAULT_POOL_SIZE: 20
